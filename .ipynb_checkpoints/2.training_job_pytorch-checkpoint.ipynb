{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training script를 이용한 training job\n",
    "이번 주제를 통해 training script를 통해 머신러닝 모델을 훈련하고 deploy하는 방법을 배웁니다.\n",
    "fastai와 pytorch를 이용한 두개의 스크립트를 이용하여 각각의 모델을 만들 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기본적인 설정\n",
    "training job을 위한 기본적인 설정을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import subprocess\n",
    "import boto3\n",
    "\n",
    "import PIL\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel\n",
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "# prefix = \"gc-sagemaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::413929759937:role/service-role/AmazonSageMaker-ExecutionRole-20220407T213778\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 코드는 system terminal에서 실행해주세요. 자신만의 유니크한 버킷명으로 변경하시고 실행햐야 합니다.\n",
    "추후 훈련시 이 버킷명으로 진행해야 합니다.\n",
    "\n",
    "```\n",
    "aws s3 mb s3://hymenoptera\n",
    "aws s3 sync /home/sagemaker-user/image_classification_on_sagemaker/hymenoptera_data s3://hymenoptera\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. pytorch\n",
    "### 3.1 training script 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./train_pytorch_resnet18.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./train_pytorch_resnet18.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "parser.add_argument('--num_epochs', type=int, default=1)\n",
    "parser.add_argument('--batch_size', type=int, default=4)\n",
    "\n",
    "# SageMaker Container environment\n",
    "parser.add_argument('--data', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "parser.add_argument('--model_dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# 학습을 위해 데이터 증가(augmentation) 및 일반화(normalization)\n",
    "# 검증을 위한 일반화\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "#         transforms.RandomRotation(degrees=(0, 180)),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = args.data\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=args.batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        start = datetime.now(timezone('Asia/Seoul')\n",
    "                            ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print('Start = {}'.format(start))\n",
    "\n",
    "        # 각 에폭(epoch)은 학습 단계와 검증 단계를 갖습니다.\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 모델을 학습 모드로 설정\n",
    "            else:\n",
    "                model.eval()   # 모델을 평가 모드로 설정\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 데이터를 반복\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 매개변수 경사도를 0으로 설정\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 순전파\n",
    "                # 학습 시에만 연산 기록을 추적\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # 학습 단계인 경우 역전파 + 최적화\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 통계\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]*100\n",
    "\n",
    "            print('{:10}: Loss - {:10.4f} | Acc - {:10.2f}%'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # 모델을 깊은 복사(deep copy)함\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        finish = datetime.now(timezone('Asia/Seoul')\n",
    "                            ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print('Finish = {}'.format(finish))\n",
    "        \n",
    "        time_elapsed = time.time() - start_time\n",
    "        print('Time: {:10.2f}m'.format(time_elapsed/60))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:10.0f}hr {:10.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600)/60))\n",
    "    print('Best val Acc: {:10.2f}%'.format(best_acc))\n",
    "\n",
    "    # 가장 나은 모델 가중치를 불러옴\n",
    "    torch.save(best_model_wts, os.path.join(args.model_dir, 'model.pth'))\n",
    "    \n",
    "    # === Save Model Parameters ===\n",
    "    logger.info(\"Model successfully saved at: {}\".format(args.model_dir)) \n",
    "\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 모든 매개변수들이 최적화되었는지 관찰\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-1, momentum=0.9)\n",
    "\n",
    "# 5에폭마다 0.1씩 학습률 감소\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(data_loader))\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7,\n",
    "                                       gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft,\n",
    "                       exp_lr_scheduler,\n",
    "                       num_epochs=args.num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-20 07:28:31 Starting - Starting the training job...\n",
      "2022-04-20 07:28:48 Starting - Preparing the instances for trainingProfilerReport-1650439711: InProgress\n",
      "......\n",
      "2022-04-20 07:30:01 Downloading - Downloading input data...\n",
      "2022-04-20 07:30:26 Training - Downloading the training image............\n",
      "2022-04-20 07:32:26 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-04-20 07:32:29,737 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-04-20 07:32:29,763 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-04-20 07:32:29,772 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-04-20 07:32:30,226 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 4,\n",
      "        \"num_epochs\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-04-20-07-28-31-380\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-413929759937/pytorch-training-2022-04-20-07-28-31-380/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_pytorch_resnet18\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_pytorch_resnet18.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":4,\"num_epochs\":2}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_pytorch_resnet18.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_pytorch_resnet18\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-413929759937/pytorch-training-2022-04-20-07-28-31-380/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":4,\"num_epochs\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-04-20-07-28-31-380\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-413929759937/pytorch-training-2022-04-20-07-28-31-380/source/sourcedir.tar.gz\",\"module_name\":\"train_pytorch_resnet18\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_pytorch_resnet18.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"4\",\"--num_epochs\",\"2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=4\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_pytorch_resnet18.py --batch_size 4 --num_epochs 2\u001b[0m\n",
      "\u001b[34mEpoch 0/1\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mStart = 2022-04-20 16:32:36\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.206 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.663 algo-1:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.663 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.663 algo-1:26 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.664 algo-1:26 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.664 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.665 algo-1:26 INFO hook.py:584] name:conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.665 algo-1:26 INFO hook.py:584] name:bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.665 algo-1:26 INFO hook.py:584] name:bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.665 algo-1:26 INFO hook.py:584] name:layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.665 algo-1:26 INFO hook.py:584] name:layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.665 algo-1:26 INFO hook.py:584] name:layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.665 algo-1:26 INFO hook.py:584] name:layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.666 algo-1:26 INFO hook.py:584] name:layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.667 algo-1:26 INFO hook.py:584] name:layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:584] name:layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:584] name:layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:584] name:layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:584] name:layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:584] name:layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:584] name:layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:584] name:layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:584] name:layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:584] name:layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:584] name:fc.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:584] name:fc.bias count_params:2\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:586] Total Trainable Params: 11177538\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.668 algo-1:26 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-04-20 07:32:37.669 algo-1:26 INFO hook.py:476] Hook is writing from the hook with pid: 26\u001b[0m\n",
      "\u001b[34mtrain     : Loss -    13.5051 | Acc -      54.51%\u001b[0m\n",
      "\u001b[34mval       : Loss -     7.5592 | Acc -      58.82%\u001b[0m\n",
      "\u001b[34mFinish = 2022-04-20 16:32:44\u001b[0m\n",
      "\u001b[34mTime:       0.12m\u001b[0m\n",
      "\u001b[34mEpoch 1/1\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mStart = 2022-04-20 16:32:44\u001b[0m\n",
      "\u001b[34mtrain     : Loss -     1.6831 | Acc -      48.36%\u001b[0m\n",
      "\u001b[34mval       : Loss -     0.6859 | Acc -      62.09%\u001b[0m\n",
      "\u001b[34mFinish = 2022-04-20 16:32:46\u001b[0m\n",
      "\u001b[34mTime:       0.05m\u001b[0m\n",
      "\u001b[34mTraining complete in          0hr          0s\u001b[0m\n",
      "\u001b[34mBest val Acc:      62.09%\u001b[0m\n",
      "\u001b[34mModel successfully saved at: /opt/ml/model\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/44.7M [00:00<?, ?B/s]#015 13%|█▎        | 5.95M/44.7M [00:00<00:00, 62.3MB/s]#015 26%|██▌       | 11.7M/44.7M [00:00<00:00, 61.6MB/s]#015 79%|███████▉  | 35.3M/44.7M [00:00<00:00, 79.5MB/s]#015100%|██████████| 44.7M/44.7M [00:00<00:00, 140MB/s] \u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/cuda/__init__.py:125: UserWarning: \u001b[0m\n",
      "\u001b[34mTesla T4 with CUDA capability sm_75 is not compatible with the current PyTorch installation.\u001b[0m\n",
      "\u001b[34mThe current PyTorch install supports CUDA capabilities sm_35 sm_52 sm_60 sm_61 sm_70 compute_70.\u001b[0m\n",
      "\u001b[34mIf you want to use the Tesla T4 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\u001b[0m\n",
      "\u001b[34mINFO:__main__:Model successfully saved at: /opt/ml/model\u001b[0m\n",
      "\u001b[34m2022-04-20 07:32:47,626 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-04-20 07:33:02 Uploading - Uploading generated training model\n",
      "2022-04-20 07:33:02 Completed - Training job completed\n",
      "Training seconds: 181\n",
      "Billable seconds: 181\n"
     ]
    }
   ],
   "source": [
    "estimator = PyTorch(entry_point='train_pytorch_resnet18.py',\n",
    "                    role=role,\n",
    "                    instance_type='ml.g4dn.xlarge',\n",
    "                    instance_count=1,\n",
    "#                     use_spot_instances = True,\n",
    "                    framework_version='1.6.0',\n",
    "                    py_version='py36',\n",
    "                    max_run = 3*24*60*60,\n",
    "                    hyperparameters = {'num_epochs': 2, \n",
    "                                       'batch_size': 4\n",
    "                                      }                       \n",
    "                   )\n",
    "\n",
    "estimator.fit('s3://hymenoptera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-413929759937/pytorch-training-2022-04-20-07-28-31-380/output/model.tar.gz'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./inference.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info('Starting loading the model')\n",
    "    logger.info('Architecting model\\'s structure')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    \n",
    "    logger.info('Loading the model weights')\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f, map_location=device))\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    logger.info('Done loading model')\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    logger.info('Generating prediction based on input parameters.')\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        return model(input_data.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---"
     ]
    }
   ],
   "source": [
    "model = PyTorchModel(\n",
    "    model_data=estimator.model_data,\n",
    "    name=estimator._current_job_name,\n",
    "    role=role,\n",
    "    framework_version=estimator.framework_version,\n",
    "    py_version=\"py36\",\n",
    "    entry_point='inference.py',\n",
    ")\n",
    "\n",
    "predictor = model.deploy(instance_type='ml.m5.xlarge',\n",
    "                                     initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "test_datasets = datasets.ImageFolder(\n",
    "    root='hymenoptera_data/val',\n",
    "    transform= transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "\n",
    "test_datasets_loaders = torch.utils.data.DataLoader(test_datasets, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = []\n",
    "true_label = []\n",
    "output_of_model = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for i, (inputs, labels) in enumerate(test_datasets_loaders):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = predictor.predict(inputs)\n",
    "            _, preds = torch.max(torch.from_numpy(outputs), 1)\n",
    "            print(preds)\n",
    "            output_of_model.append(outputs)\n",
    "            pred_label.append(preds.tolist())\n",
    "            true_label.append(labels.tolist())\n",
    "pred_label = sum(pred_label, [])\n",
    "true_label = sum(true_label, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(true_label, pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(true_label, pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 deleting endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/pytorch-1.10-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
