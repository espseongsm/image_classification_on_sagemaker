{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training script를 이용한 training job\n",
    "이번 주제를 통해 training script를 통해 머신러닝 모델을 훈련하고 deploy하는 방법을 배웁니다.\n",
    "fastai와 pytorch를 이용한 두개의 스크립트를 이용하여 각각의 모델을 만들 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기본적인 설정\n",
    "training job을 위한 기본적인 설정을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import subprocess\n",
    "import boto3\n",
    "import PIL\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel\n",
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::413929759937:role/service-role/AmazonSageMaker-ExecutionRole-20220407T213778\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 코드는 ```system terminal```에서 실행해주세요. 자신만의 유니크한 버킷명으로 변경하시고 실행햐야 합니다.\n",
    "추후 훈련시 이 버킷명으로 진행해야 합니다.\n",
    "\n",
    "```\n",
    "aws s3 mb s3://hymenoptera\n",
    "aws s3 sync /home/sagemaker-user/image_classification_on_sagemaker/hymenoptera_data s3://hymenoptera\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. training script 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./train_pytorch_resnet18.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./train_pytorch_resnet18.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "parser.add_argument('--num_epochs', type=int, default=1)\n",
    "parser.add_argument('--batch_size', type=int, default=4)\n",
    "\n",
    "# SageMaker Container 환경 설정\n",
    "parser.add_argument('--data', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "parser.add_argument('--model_dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# 학습을 위해 데이터 증가(augmentation) 및 일반화(normalization)\n",
    "# 검증을 위한 일반화\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "#         transforms.RandomRotation(degrees=(0, 180)),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = args.data\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                              batch_size=args.batch_size,\n",
    "                                              shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        start = datetime.now(timezone('Asia/Seoul')\n",
    "                            ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print('Start = {}'.format(start))\n",
    "\n",
    "        # 각 에폭(epoch)은 학습 단계와 검증 단계를 갖습니다.\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 모델을 학습 모드로 설정\n",
    "            else:\n",
    "                model.eval()   # 모델을 평가 모드로 설정\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 데이터를 반복\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 매개변수 경사도를 0으로 설정\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 순전파\n",
    "                # 학습 시에만 연산 기록을 추적\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # 학습 단계인 경우 역전파 + 최적화\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 통계\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]*100\n",
    "\n",
    "            print('{:10}: Loss - {:10.4f} | Acc - {:10.2f}%'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # 모델을 deep copy함\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "        finish = datetime.now(timezone('Asia/Seoul')\n",
    "                            ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print('Finish = {}'.format(finish))\n",
    "        \n",
    "        time_elapsed = time.time() - start_time\n",
    "        print('Time: {:10.2f}m'.format(time_elapsed/60))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:10.0f}hr {:10.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600)/60))\n",
    "    print('Best val Acc: {:10.2f}%'.format(best_acc))\n",
    "\n",
    "    # 가장 나은 모델 가중치를 불러와 저장함\n",
    "    torch.save(best_model_wts, os.path.join(args.model_dir, 'model.pth'))\n",
    "    logger.info(\"Model successfully saved at: {}\".format(args.model_dir)) \n",
    "\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 모든 매개변수들이 최적화되었는지 관찰\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-1, momentum=0.9)\n",
    "\n",
    "# 7에폭마다 0.1씩 학습률 감소\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7,\n",
    "                                       gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft,\n",
    "                       exp_lr_scheduler,\n",
    "                       num_epochs=args.num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2022-04-26-09-13-03-964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-26 09:13:04 Starting - Starting the training job...\n",
      "2022-04-26 09:13:06 Starting - Launching requested ML instancesProfilerReport-1650964384: InProgress\n",
      "......\n",
      "2022-04-26 09:14:32 Starting - Preparing the instances for training......"
     ]
    }
   ],
   "source": [
    "estimator = PyTorch(entry_point='train_pytorch_resnet18.py',\n",
    "                    role=role,\n",
    "                    instance_type='ml.g4dn.xlarge',\n",
    "                    instance_count=1,\n",
    "                    use_spot_instances = True,\n",
    "                    framework_version='1.6.0',\n",
    "                    py_version='py36',\n",
    "                    max_run = 3*24*60*60,\n",
    "                    max_wait = 2*3*24*60*60,\n",
    "                    hyperparameters = {'num_epochs': 2, \n",
    "                                       'batch_size': 4\n",
    "                                      }                       \n",
    "                   )\n",
    "\n",
    "estimator.fit('s3://hymenoptera')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델이 저장된 위치입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./inference.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger.info('Starting loading the model')\n",
    "    logger.info('Architecting model\\'s structure')\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    \n",
    "    logger.info('Loading the model weights')\n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f, map_location=device))\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    logger.info('Done loading model')\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    logger.info('Generating prediction based on input parameters.')\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        return model(input_data.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    model_data=estimator.model_data,\n",
    "    name=estimator._current_job_name,\n",
    "    role=role,\n",
    "    framework_version=estimator.framework_version,\n",
    "    py_version=\"py36\",\n",
    "    entry_point='inference.py',\n",
    ")\n",
    "\n",
    "predictor = model.deploy(instance_type='ml.m5.xlarge',\n",
    "                                     initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "test_datasets = datasets.ImageFolder(\n",
    "    root='hymenoptera_data/val',\n",
    "    transform= transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "\n",
    "test_datasets_loaders = torch.utils.data.DataLoader(test_datasets, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = []\n",
    "true_label = []\n",
    "output_of_model = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for i, (inputs, labels) in enumerate(test_datasets_loaders):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = predictor.predict(inputs)\n",
    "            _, preds = torch.max(torch.from_numpy(outputs), 1)\n",
    "            print(preds)\n",
    "            output_of_model.append(outputs)\n",
    "            pred_label.append(preds.tolist())\n",
    "            true_label.append(labels.tolist())\n",
    "pred_label = sum(pred_label, [])\n",
    "true_label = sum(true_label, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(true_label, pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(true_label, pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. deleting endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.10 Python 3.8 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/pytorch-1.10-cpu-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
