{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training script를 이용한 training job\n",
    "이번 주제를 통해 training script를 통해 머신러닝 모델을 훈련하고 deploy하는 방법을 배웁니다.\n",
    "fastai와 pytorch를 이용한 두개의 스크립트를 이용하여 각각의 모델을 만들 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기본적인 설정\n",
    "training job을 위한 기본적인 설정을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import subprocess\n",
    "import boto3\n",
    "\n",
    "import PIL\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel\n",
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "# prefix = \"gc-sagemaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::413929759937:role/service-role/AmazonSageMaker-ExecutionRole-20220330T131248\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-ap-northeast-2-413929759937'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. pytorch\n",
    "### 3.1 training script 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./train_pytorch_resnet18.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./train_pytorch_resnet18.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "parser.add_argument('--num_epochs', type=int, default=1)\n",
    "parser.add_argument('--batch_size', type=int, default=4)\n",
    "\n",
    "# SageMaker Container environment\n",
    "parser.add_argument('--data', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "parser.add_argument('--model_dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "# 학습을 위해 데이터 증가(augmentation) 및 일반화(normalization)\n",
    "# 검증을 위한 일반화\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "#         transforms.RandomRotation(degrees=(0, 180)),\n",
    "#         transforms.RandomHorizontalFlip(),\n",
    "#         transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = args.data\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=args.batch_size,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        start = datetime.now(timezone('Asia/Seoul')\n",
    "                            ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print('Start = {}'.format(start))\n",
    "\n",
    "        # 각 에폭(epoch)은 학습 단계와 검증 단계를 갖습니다.\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 모델을 학습 모드로 설정\n",
    "            else:\n",
    "                model.eval()   # 모델을 평가 모드로 설정\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 데이터를 반복\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 매개변수 경사도를 0으로 설정\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 순전파\n",
    "                # 학습 시에만 연산 기록을 추적\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # 학습 단계인 경우 역전파 + 최적화\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 통계\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]*100\n",
    "\n",
    "            print('{:10}: Loss - {:10.4f} | Acc - {:10.2f}%'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # 모델을 깊은 복사(deep copy)함\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "#                 best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                best_model = model\n",
    "            \n",
    "        finish = datetime.now(timezone('Asia/Seoul')\n",
    "                            ).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        print('Finish = {}'.format(finish))\n",
    "        \n",
    "        time_elapsed = time.time() - start_time\n",
    "        print('Time: {:10.2f}m'.format(time_elapsed/60))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:10.0f}hr {:10.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600)/60))\n",
    "    print('Best val Acc: {:10.2f}%'.format(best_acc))\n",
    "\n",
    "    # 가장 나은 모델 가중치를 불러옴\n",
    "    torch.save(best_model, os.path.join(args.model_dir, 'model.pth'))\n",
    "    \n",
    "    # === Save Model Parameters ===\n",
    "    logger.info(\"Model successfully saved at: {}\".format(args.model_dir)) \n",
    "\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 모든 매개변수들이 최적화되었는지 관찰\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=1e-1, momentum=0.9)\n",
    "\n",
    "# 5에폭마다 0.1씩 학습률 감소\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(data_loader))\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7,\n",
    "                                       gamma=0.1)\n",
    "\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft,\n",
    "                       exp_lr_scheduler,\n",
    "                       num_epochs=args.num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2022-04-06-07-05-03-713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-06 07:05:04 Starting - Starting the training job...\n",
      "2022-04-06 07:05:30 Starting - Preparing the instances for trainingProfilerReport-1649228703: InProgress\n",
      "......\n",
      "2022-04-06 07:06:30 Downloading - Downloading input data...\n",
      "2022-04-06 07:06:50 Training - Downloading the training image...\n",
      "2022-04-06 07:07:31 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-04-06 07:07:22,451 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-04-06 07:07:22,454 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-04-06 07:07:22,463 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-04-06 07:07:22,468 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-04-06 07:07:22,746 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-04-06 07:07:22,758 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-04-06 07:07:22,769 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-04-06 07:07:22,780 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 4,\n",
      "        \"num_epochs\": 2\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-04-06-07-05-03-713\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-413929759937/pytorch-training-2022-04-06-07-05-03-713/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_pytorch_resnet18\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_pytorch_resnet18.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":4,\"num_epochs\":2}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_pytorch_resnet18.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_pytorch_resnet18\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-413929759937/pytorch-training-2022-04-06-07-05-03-713/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":4,\"num_epochs\":2},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-04-06-07-05-03-713\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-413929759937/pytorch-training-2022-04-06-07-05-03-713/source/sourcedir.tar.gz\",\"module_name\":\"train_pytorch_resnet18\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_pytorch_resnet18.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"4\",\"--num_epochs\",\"2\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=4\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=2\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_pytorch_resnet18.py --batch_size 4 --num_epochs 2\u001b[0m\n",
      "\u001b[34mEpoch 0/1\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mStart = 2022-04-06 16:07:25\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.217 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.461 algo-1:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.461 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.462 algo-1:26 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.462 algo-1:26 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.462 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:conv1.weight count_params:9408\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.0.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.0.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.0.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.0.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.0.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.0.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.1.conv1.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.1.bn1.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.1.bn1.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.1.conv2.weight count_params:36864\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.1.bn2.weight count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.529 algo-1:26 INFO hook.py:584] name:layer1.1.bn2.bias count_params:64\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.0.conv1.weight count_params:73728\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.0.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.0.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.0.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.0.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.0.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.0.downsample.0.weight count_params:8192\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.0.downsample.1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.0.downsample.1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.1.conv1.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.1.bn1.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.1.bn1.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.1.conv2.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.1.bn2.weight count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer2.1.bn2.bias count_params:128\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer3.0.conv1.weight count_params:294912\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer3.0.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer3.0.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer3.0.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer3.0.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer3.0.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer3.0.downsample.0.weight count_params:32768\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.530 algo-1:26 INFO hook.py:584] name:layer3.0.downsample.1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer3.0.downsample.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer3.1.conv1.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer3.1.bn1.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer3.1.bn1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer3.1.conv2.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer3.1.bn2.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer3.1.bn2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.0.conv1.weight count_params:1179648\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.0.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.0.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.0.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.0.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.0.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.0.downsample.0.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.0.downsample.1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.0.downsample.1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.1.conv1.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.1.bn1.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.1.bn1.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.1.conv2.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.1.bn2.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:layer4.1.bn2.bias count_params:512\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:fc.weight count_params:1536\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:584] name:fc.bias count_params:3\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.531 algo-1:26 INFO hook.py:586] Total Trainable Params: 11178051\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.532 algo-1:26 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-04-06 07:07:25.534 algo-1:26 INFO hook.py:476] Hook is writing from the hook with pid: 26\u001b[0m\n",
      "\u001b[34mtrain     : Loss -    15.7949 | Acc -      54.10%\u001b[0m\n",
      "\u001b[34mval       : Loss -     9.9094 | Acc -      57.52%\u001b[0m\n",
      "\u001b[34mFinish = 2022-04-06 16:07:49\u001b[0m\n",
      "\u001b[34mTime:       0.41m\u001b[0m\n",
      "\u001b[34mEpoch 1/1\u001b[0m\n",
      "\u001b[34m----------\u001b[0m\n",
      "\u001b[34mStart = 2022-04-06 16:07:49\u001b[0m\n",
      "\u001b[34mtrain     : Loss -     0.7691 | Acc -      55.33%\u001b[0m\n",
      "\u001b[34mval       : Loss -     1.9723 | Acc -      54.90%\u001b[0m\n",
      "\u001b[34mFinish = 2022-04-06 16:08:14\u001b[0m\n",
      "\u001b[34mTime:       0.41m\u001b[0m\n",
      "\u001b[34mTraining complete in          0hr          1s\u001b[0m\n",
      "\u001b[34mBest val Acc:      57.52%\u001b[0m\n",
      "\u001b[34mModel successfully saved at: /opt/ml/model\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/44.7M [00:00<?, ?B/s]#015 12%|█▏        | 5.23M/44.7M [00:00<00:00, 54.9MB/s]#015 24%|██▍       | 10.9M/44.7M [00:00<00:00, 56.3MB/s]#015 90%|█████████ | 40.2M/44.7M [00:00<00:00, 74.5MB/s]#015100%|██████████| 44.7M/44.7M [00:00<00:00, 149MB/s] \u001b[0m\n",
      "\u001b[34mINFO:__main__:Model successfully saved at: /opt/ml/model\u001b[0m\n",
      "\u001b[34m2022-04-06 07:08:14,623 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-04-06 07:08:31 Uploading - Uploading generated training model\n",
      "2022-04-06 07:08:51 Completed - Training job completed\n",
      "Training seconds: 128\n",
      "Billable seconds: 128\n"
     ]
    }
   ],
   "source": [
    "estimator = PyTorch(entry_point='train_pytorch_resnet18.py',\n",
    "                    role=role,\n",
    "#                     instance_type='ml.g4dn.xlarge',\n",
    "                    instance_type='ml.m5.2xlarge',\n",
    "                    instance_count=1,\n",
    "                    framework_version='1.6.0',\n",
    "                    py_version='py36',\n",
    "                    max_run = 3*24*60*60,\n",
    "                    hyperparameters = {'num_epochs': 2, \n",
    "                                       'batch_size': 4\n",
    "                                      }                       \n",
    "                   )\n",
    "# s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}'.format(bucket, prefix), content_type='csv')    \n",
    "#s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}'.format(bucket, prefix), content_type='csv') # SDK v1\n",
    "estimator.fit('s3://hymenoptera')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-northeast-2-413929759937/pytorch-training-2022-04-06-07-05-03-713/output/model.tar.gz'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./inference.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "import requests\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(1)\n",
    "    logger.info('Loading the model')\n",
    "    print(2)\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    print(3)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    print(4)\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    print(5)\n",
    "    \n",
    "    with open(os.path.join(model_dir, 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f, map_location=device), strict=False)\n",
    "#         model.load_state_dict(torch.load(f))\n",
    "    print(6)    \n",
    "    model.to(device).eval()\n",
    "    print(7)\n",
    "    logger.info('Done loading model')\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    logger.info('Generating prediction based on input parameters.')\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        return model(input_data.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: pytorch-training-2022-04-06-07-05-03-713\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-training-2022-04-06-07-09-21-588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "model = PyTorchModel(\n",
    "    model_data=estimator.model_data,\n",
    "    name=estimator._current_job_name,\n",
    "    role=role,\n",
    "    framework_version=estimator.framework_version,\n",
    "    py_version=\"py36\",\n",
    "    entry_point='inference.py',\n",
    ")\n",
    "\n",
    "predictor = model.deploy(instance_type='ml.m5.xlarge',\n",
    "                                     initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "test_datasets = datasets.ImageFolder(\n",
    "    root='hymenoptera_data/val',\n",
    "    transform= transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]))\n",
    "\n",
    "test_datasets_loaders = torch.utils.data.DataLoader(test_datasets, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://ap-northeast-2.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-2#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-2022-04-06-07-09-21-588 in account 413929759937 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8c856957fd5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received server error (0) from primary with message \"Your invocation timed out while waiting for a response from container primary. Review the latency metrics for each container in Amazon CloudWatch, resolve the issue, and try again.\". See https://ap-northeast-2.console.aws.amazon.com/cloudwatch/home?region=ap-northeast-2#logEventViewer:group=/aws/sagemaker/Endpoints/pytorch-training-2022-04-06-07-09-21-588 in account 413929759937 for more information."
     ]
    }
   ],
   "source": [
    "pred_label = []\n",
    "true_label = []\n",
    "output_of_model = []\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for i, (inputs, labels) in enumerate(test_datasets_loaders):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = predictor.predict(inputs)\n",
    "            _, preds = torch.max(torch.from_numpy(outputs), 1)\n",
    "            print(preds)\n",
    "            output_of_model.append(outputs)\n",
    "            pred_label.append(preds.tolist())\n",
    "            true_label.append(labels.tolist())\n",
    "pred_label = sum(pred_label, [])\n",
    "true_label = sum(true_label, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 0), dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(true_label, pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(true_label, pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 deleting endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: pytorch-training-2022-04-06-07-09-21-588\n",
      "INFO:sagemaker:Deleting endpoint with name: pytorch-training-2022-04-06-07-09-21-588\n"
     ]
    }
   ],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-2:806072073708:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
